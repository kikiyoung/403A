---
title: "403BfinalprojectUber"
date: "3/7/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r libraries, include=FALSE}
library(tis)
library('tseries')
library("forecast")
library(Metrics)
library(MASS)
library(vars)
library(fGarch)
```
## I. Introduction 


#Data clean 

```{r}
## import data 
rm(list=ls(all=TRUE))
setwd("/Users/Desktop/winter/403B/final project")
ub=read.csv("uberdata.csv",header = T)
temp = read.csv("tempre.csv",header = T)
```
## II. Data Exploratory

### II.1 Data Quality
```{r}
### find missing value 
sum(is.na(ub))
sum(is.na(temp$Precip))
```

There are 39 NAs in total in dataset "ub", 0 NAs in dataset "temp". 

 subsitute NAs, by: if NA, then NA value = average of the the the day before and the day after 
   eg. day 10th is NA, X10 = (X9 + X11)/2
   both ub[285,] ub[286,] are NA, so we define ub[285,] = ub[284,],ub[286,] = ub[287]
  
```{r}
  ### define NAs in ub 
index1 = which(is.na(ub$mean),arr.ind = T)
for (i in index1){
  ub$lower[i] = (ub$lower[i-1] + ub$lower[i+1])/2
  ub$upper[i] = (ub$upper[i-1] + ub$upper[i+1])/2
  ub$mean[i] = (ub$upper[i] + ub$lower[i] )/2
}
ub[285,2:4] = ub[284,2:4]
ub[286,2:4] = ub[287,2:4]

  ### define NAs in precip
precip = temp$Precip[1:365]
index2 = levels(precip)
for (i in 1:length(precip)){
  if (precip[i] == 'T') {
    precip[i] = 0
  } else if (precip[i] == ''){
    precip[i] = NA
  } else {
    for (j in index2[2:22]) {
      if (precip[i] == j) {
        precip[i] = as.numeric(j)
      }
    }
  }
}
index3 = which(is.na(precip))
 ## all NAs define as 0
precip[index3] = 0

```
Define dataset:
```{r}

travel = ub$mean
travelrange = ub$upper - ub$lower
holiday = ub$holiady
  ## we will not use temp so I commented these two lines 
#meantemp = (as.numeric(temp$High) + as.numeric(temp$low) )/2
#temprange = as.numeric(temp$High) - as.numeric(temp$low) 
  # create dummy variable rainfall 
rainfall = rep(1,365)
rainfall[precip == 0] = 0 
```

### II.2 Dummy Variables Creatation 
```{r}
weekdayloop = rep(1:7,53)
weekdayloop = weekdayloop[1:365]

Sun = rep(0,365)
Sun[weekdayloop == 1] = 1
Mon = rep(0,365)
Mon[weekdayloop == 2] = 1
Tue = rep(0,365)
Tue[weekdayloop == 3] = 1
Wed = rep(0,365)
Wed[weekdayloop == 4] = 1
Thur = rep(0,365)
Thur[weekdayloop == 5] = 1
Fri = rep(0,365)
Fri[weekdayloop == 6] = 1
Sat = rep(0,365)
Sat[weekdayloop == 7] = 1

```


```{r}
  #combine dataset 
ubdata = data.frame(travel,travelrange,holiday,rainfall,Mon,Tue,Wed,Thur,Fri,Sat,Sun)

```

### II.3 Time Series Classfication, Plot and Observation
```{r}
inds <- seq(as.Date("2017-04-01"), as.Date("2018-03-01"), by = "day")

#myts <- ts(rnorm(length(inds)),     # random data
#           start = c(2014, as.numeric(format(inds[1], "%j"))),
#           frequency = 365)
#ubts =ts(ubdata$travel,start=c(2017,as.numeric(format(inds[1],"%j"))),freq=365)
ubts =ts(ubdata$travel, start = c(1, 1), freq = 7)
ubrangets =ts(ubdata$travelrange,start=c(2017,as.numeric(format(inds[1],"%j"))),freq=365)
```

#### (a) Time Series Plot
```{r}
plot(ubts,col='skyblue3',main="Change in Mean Travel Time by Uber")
plot(ubrangets,col='skyblue3',main="Change in Travel Time Range by Uber")
```

#### (b) Covariance Stationary
```{r}
library(tseries)
adf.test(ubts)
adf.test(ubrangets)
## stationary 
```

According to the results, since the p-value is smaller than 0.05, we could conclude that our time series is stationery. There is no need for transforming. 

#### (c) Plot and Discuss the ACF and PACF 
```{r}
acf(ubts)
pacf(ubts)
acf(ubrangets)
pacf(ubrangets)
```

From the graph, we could notice that there exists a circle of seven days, which is the same as days in a week. 

#### (d) 1st difference  
```{r}
ubts.1 <- diff(ubts, 1)
ubts.1.7 <- diff(ubts.1, 7)
summary(ur.df(ubts.1.7, type = "none"))
```

### III linear regression
#### (a) pure season dummy 
```{r}
m2 =lm(ubts ~ Mon+Tue+Sat+Sun+Thur+Wed)
m3 =lm(ubts ~ Mon+Tue+Sat+Sun+Thur+Fri)
m4 =lm(ubts ~ Mon+Tue+Sat+Fri+Thur+Wed)
m5 =lm(ubts ~ Sun+Tue+Sat+Fri+Thur+Wed)
m6 =lm(ubts ~ Mon+Sun+Sat+Fri+Thur+Wed)
## comparisons 
AIC(m1,m2,m3,m4,m5,m6)
summary(m6)
```

#### (b) add holiday and rainfall
```{r}
m7=lm(ubts ~ Mon+Tue+Sat+Sun+Thur+Wed+Fri+holiday)
summary(m7)

m8=lm(ubts~Mon+Tue+Sat+Sun+Thur+Wed+Fri+rainfall)
summary(m8)
```

### IV Model 
#### (a) arima 
```{r}
## arma(6,1)+seasonality
fit.a.1 <- arima(ubts, order = c(6, 1, 0), seasonal = list(order = c(7, 1, 0)))
confint(fit.a.1) 
tsdiag(fit.a.1) 
Box.test(fit.a.1$residuals, lag = 14, type = "Ljung-Box") 
plot(forecast(fit.a.1, h = 7))
summary(fit.a.1, h = 7)
# plot the estimated seasonal factors and interpret your plot

#install.packages("lmtest")
#coeftest(fit.a.1) 

fit.a.1$coef

plot(fit.a.1$coef[7:13],type='l',ylab='Seasonal Factors',xlab="Season",lwd=2, main="Plot of Seasonal Factors")
fit.b.1 <- arima(ubts, order = c(1, 1, 1), seasonal = list(order = c(0, 1, 1)))
confint(fit.b.1)
tsdiag(fit.b.1)
Box.test(fit.b.1$residuals, lag = 14, type = "Ljung-Box")
plot(forecast(fit.b.1, h = 7))
```

####(b) GARCH
```{r}
## ARCH(1)
res.arimab=fit.b.1$res
acf(res.arimab)
acf(res.arimab^2)
squared=res.arimab^2
m_g<-garchFit(res.arimab~garch(1,3),trace = FALSE)
res<-m_g@residuals/m_g@sigma.t
acf(res)
acf(res^2)
summary(m_g)
```


```{r}
forecast212=forecast(fit.b.1,12,level=95) 
plot(forecast212)
mgg<-garch(res.arimab,order=c(1,3),trace=FALSE)
summary(mgg)
ht.mg =mgg$fit[,1]^2 #use 1st column of fit plot(ht.arch08,main='Conditional variances')
plot(ht.mg,main='Conditional variances')
res212<-mgg$residuals
fit212=fitted.values(fit.b.1) 
low=fit212-1.76*sqrt(ht.mg) 
high=fit212+1.76*sqrt(ht.mg) 
plot(ubts,type='l',main='Uber,Low,High') 
lines(low,col='red')
lines(high,col='blue')

```


```{r}
## normal ditribution 
qqnorm(fit.b.1$residuals,main='ARIMA Residuals')
qqline(fit.b.1$residuals)
archres=res212
qqnorm(archres,main='ARIMA-ARCH Residuals')
qqline(archres)
```

#### (c) Garch + arima
```{r}
mag<-garchFit(formula =ubts.1~arma(1,1,1)+res.arimab~garch(1,3),cond.dist ="std",trace=FALSE) 
resi=mag@residuals/mag@sigma.t   ###Standardised Residuals 
acf(resi) 
fit_value<-fitted(mag)
plot(fit_value,type="l")

AIC(mgg,fit.b.1)
BIC(mgg,fit.b.1)
```

#### (d) Kalman kilter 
```{r}
library(TSPred)
library(KFAS)


fitkf<-fittestArimaKF(ubts, timeseries.test=NULL, h=12, na.action=na.omit,
level=0.9, filtered = TRUE, initQ=NULL,rank.by="AIC")

pred <- fitkf$pred

#extracting Kalman filtered and smoothed time series from the best fitted model
fs <- KFAS::KFS(fitkf$model,filtering=c("state","mean"),smoothing=c("state","mean"))
f <- fitted(fs, filtered = TRUE) #Kalman filtered time  series
s <- fitted(fs) #Kalman smoothed time  series
#plotting the time series data
plot(ubts,type='l',lwd=2,xlab="Time",ylab="uberts")
#plotting the Kalman filtered time series
lines(f,col='red',lty=2,lwd=2)
#plotting the Kalman smoothed time series
lines(s,col='green',lty=2,lwd=2)
#plotting predicted values
lines(ts(pred$mean,start = 2017.4),lwd=2,col='blue')
#plotting prediction intervals
lines(ts(pred$upper,start = 2017.4),lwd=2,col='light blue')
lines(ts(pred$lower,start = 2017.4),lwd=2,col='light blue')

```

### VAR
```{r}
# Look at the data
prec =ts(precip,start=c(2017,as.numeric(format(inds[1],"%j"))),freq=365 )
ubts =ts(ubdata$travel,start=c(2017,as.numeric(format(inds[1],"%j"))),freq=365)

plot(prec)
nberShade()
lines(prec,ylab="Precipitation and Mean Travel Time by Uber")
legend("topright",legend=c("Precipitation"),text.col=c("black"),bty="n")
```

```{r}
# Look at the ACF, PACF, and CCF (cros-correlation function)
tsdisplay(prec,main="Precipitation")
tsdisplay(ubts,main="Mean Travel Time by Uber")
ccf(prec,ubts,ylab="Cross-Correlation Function", main = "Precipitation and Mean Travel Time by Uber CCF")
```

```{r}
# Fit a VAR(p) model to the data
# Combine the variables into 1 data frame first:
y=cbind(prec, ubts)
#y_ts=ts.union(starts, comps) # You can also use this function
y_tot=data.frame(y)
```


```{r}
# To fit a VAR(p) model, simply call 'VAR' and set p=value
y_tot<-y_tot[1:365,]
y_model=VAR(y_tot,p=4)
summary(y_model)
# We interpret the coefficients in the usual way,but now have a
# system of equations. For example, for VAR(1) we have:
# y1 = c11 y(1,t-1) + c12 y(2,t-1)
# y2 = c21 y(1,t-1) + c22 y(2,t-1)
# The ourtput from summary are cij, cov, and corr.
```
```{r}
# Plot the fit and orginal data
quartz()
plot(y_model)
```


```{r}
# Look at ACF and PACf
par(mfrow=c(2,1))
acf(residuals(y_model)[,1])
pacf(residuals(y_model)[,1])

par(mfrow=c(2,1))
acf(residuals(y_model)[,2])
pacf(residuals(y_model)[,2])
```
```{r}
tsdisplay(residuals(y_model)[,2],main ="Comps = prec(t-k) + ubts(t-k)")

```
```{r}
# Impulse Response Function
irf(y_model)
#quartz()
#pdf("irf.pdf", width=8, height=8) 
plot(irf(y_model, n.ahead=36))
#dev.off() 
```

```{r}
#Forecast
#holdout_matrix = hold out data
#var.predict = predict(object=y_model, n.ahead=52, dumvar=holdout_matrix);
var.predict = predict(object=y_model, n.ahead=52)
plot(var.predict)
dev.print(device=postscript,"forecast.eps",width=7,height=7, horizontal=FALSE)
#dev.off()

#Granger Test
grangertest(ubts ~ prec, order = 8)

#Variance Decomposition (Forecast Error Variance Decomposition)
#plot(fevd(y_model, n.ahead = 5))

#CUSUM Plot
#plot(stability(y_model, type = "Rec-CUSUM"), plot.type="single")
```

